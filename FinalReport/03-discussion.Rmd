# Discussion

With the implementation from this project, a trajectory planning methodology that is capable of detecting the obstacle with camera has been implemented. In this section, analysis on the RRT algorithm, error rate and source for the measurement with RealSense camera, limitation for the real-time implementation and future work will be discussed. 

The advantage for RRT algorithm is that a collision avoidance path from initial point to the destination would for sure be created, as long as it exists. However, as the algorithm will generate random points to build the tree exhaustively, the computation time will increase dramatically when the obstacles are close to the destination point, which showed in figure \@ref(fig:figure2). It is important to choose a proper value for the step size between each node on RRT. If the step size is too small, there will be too many nodes to be generated between the two points on the map. This would increase the calculation time. However, if the step size is too large, chances for finding a proper path between obstacles would be decreased, especially for those anomaly shape paths between two obstacles.  

The objects captured by the camera were measured. The measurement result defines the scale for transferring the obstacle to the map canvas. In order to increase the accuracy for the measurement, several reference objects have been used for calibration. However, the error rate for the measurement ranges from 0.48% - 12.6%. We noticed that when the object to be measured has a flat surface whose distance to the camera is about the same across the surface and has a regular shape such as rectangle, the error rate would be lower. And when the object has an irregularly or convex shape such as cylinder, the error rate would be higher. The reason is that the depth information for the flat surface is mostly uniform, but the depth information on the cylindrical surface varying. Current calculation for measurement is based on the depth info at the center point of the object. Therefore, there will be a bias on the depth value. Similarly, the error from varying depth value would be introduced if the surface is not facing the camera perpendicularly. To solve this problem, we could use 3D coordination which combined both RGB and depth information for the measurement. 

A limitation for the current implementation is the path planning is not online. Currently, the scripts are importing the recorded video for image processing and object detection. Then the processed results were imported as obstacle information to the pathway planning algorithm. The video reading process take more than 10s to finish and this set a bottleneck in implementing it in real-time. As the SDK for RealSense camera are implemented with C++, the development environment should be changed to C++ for further implementation.

In the future, there are two main directions for this project to be continued. One is the implementation of the object detection in real-time with OpenCV packages provided by RealSense. With the RealSense SDK, saving the internal processed result of the video streaming is no longer needed. The depth information detected in real-time will be input directly to the object detection function, converted to top view and then added on the pre-defined map for the next path planning calculation. The other direction for the future work is the control algorithm for path following. A feedback control algorithm should be implemented to support the drone to follow the planned path properly. At the end, a real-time system combining the functions of obstacle detection, path planning and path tracking would fully support the atonomous navigation of the robotic system. 