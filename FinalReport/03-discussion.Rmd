# Discussion

With the implementation from this project, a trajectory planning methodology that is capable of detecting the obstacle with camera has been implemented. In this section, analysis on the RRT algorithm, error rate and source for the measurement with RealSense camera, limitation of the implementation and future work will be discussed. 

The advantage for RRT algorithm is that a collision avoidance path from initial point to the destination would for sure be created, as long as it exists. However, as the algorithm will generate random points to build the tree exhaustively, the computation time will increase dramatically when the obstacles are close to the destination point, which showed in figure \@ref(fig:figure2). It is important to choose a proper value for the step size between each node on RRT. If the step size is too small, there will be too many nodes to be generated between the two points on the map. This would increase the calculation time. However, if the step size is too large, chances for finding a proper path between obstacles would be decreased, especially for those anomaly shape paths between two obstacles.  

The objects captured by the camera were measured. The measurement result defines the scale for transferring the obstacle to the map canvas. In order to increase the accuracy for the measurement, several reference objects have been used for calibration. However, the error rate for the measurement ranges from 0.48% - 12.6%. We noticed that when the object to be measured has a flat surface whose distance to the camera is about the same across the surface and has a regular shape such as rectangle, the error rate would be lower. And when the object has an irregularly or convex shape such as cylinder, the error rate would be higher. The reason is that the depth information for the flat surface is mostly uniform, but the depth information on the cylindrical surface varying. Current calculation for measurement is based on the depth info at the center point of the object. Therefore, there will be a bias on the depth value. Similarly, the error from varying depth value would be introduced if the surface is not facing the camera perpendicularly. To solve this problem, we could use 3D coordination which combined both RGB and depth information for the measurement. 

Another limitation for the current implementation for obstacle detection is the usage of minimum volume ellipsoid algorithm. With this algorithm, an ellipsoid would be generated around the obstacles with anomaly shape. This would increase the safety by avoiding a path that goes inside the anomaly shaped obstacles and causing the drone or robot trapped. However, this algorithm only calculates one ellipsoid at a time. It would output one large ellipsoid if there are multiple obstacles scatter on the map. Some classifications should be done before using this algorithm.

One more limitation for the current implementation is that the path planning is not online. Currently, the scripts are importing the recorded video for image processing and object detection. Then the processed results are imported as obstacle information to the pathway planning algorithm. The video reading process take more than 10s to finish and this set a bottleneck in implementing it in real-time with MATLAB. As the SDK for RealSense camera supports real-time image processing, the development environment should be changed to C++ for further implementation to take advantage of the RealSense SDK application.

In the future, there are several directions for this project to be continued. One is the implementation of the object detection in real-time with OpenCV packages provided by RealSense. With the RealSense SDK, saving the internal processed result of the video streaming is no longer needed. The depth information detected in real-time will be input directly to the object detection function, converted to top view and then added on the pre-defined map for the next path planning calculation. Another direction of future work could be improving the algorithm of the pathway planning and obstacle detection. Also, a feedback control algorithm should be implemented to support the drone or robot to follow the planned path properly. At the end, a real-time system combining the functions of obstacle detection, path planning and path tracking would fully support the autonomous navigation of the robotic system. 